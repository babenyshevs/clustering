{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# other\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# src\n",
    "from src.general.io import to_pickle, from_pickle\n",
    "from src.features.nlp import lemmatize, tokenize, filter_text_column, filter_rows_with_string, generate_ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PATHS & NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "RAW_DATA_PATHS = {}\n",
    "for short_name, filename in zip([\"feb\", \"mar\", \"apr\", \"may\", \"feedback\"],\n",
    "                                [\"event_stg_user_input_web_cw6.txt\",\n",
    "                                \"event_stg_user_input_web_cw10.txt\",\n",
    "                                \"event_stg_user_input_web_cw15.txt\",\n",
    "                                \"event_stg_user_input_web_cw19.txt\",\n",
    "                                \"current_user_feedback_text.xlsx\",\n",
    "                                ]):\n",
    "    RAW_DATA_PATHS[short_name] = f\"..{os.getenv('RAW_DATA_DIR')}/{filename}\"\n",
    "\n",
    "\n",
    "EXT_DATA_PATHS = {}\n",
    "for short_name, filename in zip([\"rasa\"],\n",
    "                                [\"rasa_train_data.pkl\"]):\n",
    "    EXT_DATA_PATHS[short_name] = f\"..{os.getenv('EXTERNAL_DATA_DIR')}/{filename}\"\n",
    "\n",
    "\n",
    "INTERIM_DATA_PATHS = {}\n",
    "for short_name, filename in zip([\"rasa_docs\", \"rasa_emb\"],\n",
    "                                [\"rasa_docs.pkl\",\n",
    "                                \"rasa_embedings.pkl\",\n",
    "                                ]):\n",
    "    INTERIM_DATA_PATHS[short_name] = f\"..{os.getenv('INTERIM_DATA_DIR')}/{filename}\"\n",
    "\n",
    "# add more interims\n",
    "for short_name in RAW_DATA_PATHS.keys():\n",
    "    INTERIM_DATA_PATHS[f\"{short_name}_doc\"] = f\"..{os.getenv('INTERIM_DATA_DIR')}/{short_name}_docs.pkl\"\n",
    "    INTERIM_DATA_PATHS[f\"{short_name}_emb\"] = f\"..{os.getenv('INTERIM_DATA_DIR')}/{short_name}_embeding.pkl\"\n",
    "    INTERIM_DATA_PATHS[f\"{short_name}_tok\"] = f\"..{os.getenv('INTERIM_DATA_DIR')}/{short_name}_tokens.pkl\"\n",
    "\n",
    "\n",
    "EDA_REPORT_PATHS = {}\n",
    "for short_name in RAW_DATA_PATHS.keys():\n",
    "    EDA_REPORT_PATHS[short_name] = f\"..{os.getenv('REPORT_DIR')}/eda_{short_name}.html\"\n",
    "\n",
    "\n",
    "SBERT_PATH = f\"..{os.getenv('MODELS_DIR')}/sbert\"\n",
    "\n",
    "\n",
    "# Feedback data variables\n",
    "KEEP_COLS_FEEDBACK = [\"session_id\"\n",
    "                        ,\"created_dt\"\n",
    "                        ,\"channel\"\n",
    "                        ,\"feedback_text_list\"\n",
    "                        ,\"dialog_engine\"\n",
    "                        ,\"topic_list\"\n",
    "                        ,\"topic_count\"]\n",
    "\n",
    "# User input variables\n",
    "KEEP_COLS_USERINPUT = [\"session_id\"\n",
    "                        ,\"event_id\"\n",
    "                        ,\"created_dt\"\n",
    "                        ,\"user_input\"\n",
    "                        ,\"top_intent_1\"\n",
    "                        ,\"content_version\"]\n",
    "                        \n",
    "TEXT_COL_USERINPUT = \"user_input\"\n",
    "ID_COL_USERINPUT = \"session_id\"\n",
    "\n",
    "N_TOPICS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeding_model = SentenceTransformer(SBERT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feedback data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback = pd.read_excel(RAW_DATA_PATHS[\"feedback\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = feedback.loc[:,KEEP_COLS_FEEDBACK]\n",
    "feedback_docs = df[\"feedback_text_list\"].to_list()\n",
    "to_pickle(feedback_docs, INTERIM_DATA_PATHS[\"feedback_doc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rasa NLU training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rasa_data = from_pickle(EXT_DATA_PATHS[\"rasa\"])\n",
    "rasa_docs = rasa_data[\"example\"].to_list()\n",
    "to_pickle(rasa_docs, INTERIM_DATA_PATHS[\"rasa_docs\"])\n",
    "\n",
    "rasa_embedings = np.vstack(rasa_data[\"embeding\"].to_numpy())\n",
    "to_pickle(rasa_embedings, INTERIM_DATA_PATHS[\"rasa_emb\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User input examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "month='may': : 4it [02:01, 30.38s/it]\n"
     ]
    }
   ],
   "source": [
    "months_to_process = [\"feb\", \"mar\", \"apr\", \"may\"]\n",
    "pbar = tqdm(len(months_to_process))\n",
    "\n",
    "for month in months_to_process:\n",
    "    pbar.set_description(f\"{month=}\")\n",
    "    # read data\n",
    "    df = pd.read_csv(RAW_DATA_PATHS[month], sep='|', low_memory=False)\n",
    "\n",
    "    # clean up - keep TKS only, omit number inputs and spec characters\n",
    "    cleant = filter_text_column(df, TEXT_COL_USERINPUT)\n",
    "    cleant = filter_rows_with_string(cleant, \"tks\", \"top_intent_1\")\n",
    "\n",
    "    # group conversation into one sentence\n",
    "    grouped = cleant.groupby(ID_COL_USERINPUT)[TEXT_COL_USERINPUT].apply(' '.join).reset_index()\n",
    "    \n",
    "    docs = grouped[TEXT_COL_USERINPUT].to_list()\n",
    "    to_pickle(docs, INTERIM_DATA_PATHS[f\"{month}_doc\"])\n",
    "\n",
    "    # embedings = grouped[TEXT_COL_USERINPUT].apply(model.encode).to_numpy() #np.vstack()\n",
    "    # to_pickle(embedings, INTERIM_DATA_PATHS[f\"{month}_emb\"])\n",
    "\n",
    "    lemmatized_docs = lemmatize(docs=docs, model_name=\"de_core_news_lg\")\n",
    "    tokens = tokenize(docs=lemmatized_docs)\n",
    "    tokens = generate_ngrams(tokens, n=4)\n",
    "    to_pickle(tokens, INTERIM_DATA_PATHS[f\"{month}_tok\"])\n",
    "\n",
    "    pbar.update(1)\n",
    "    \n",
    "pbar.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
